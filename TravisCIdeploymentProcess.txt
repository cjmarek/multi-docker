Travis CI deployment process. Build pipeline.

Anytime that we make a change to our GitHub Repository, Travis is going to
automatically pull down our gitHub repo, and build out a new set of production images
and push them off to DockerHub.

So how are we going to use these images and actually deploy them, in production.
For that we are going to be using amazon elastic beanstalk.

Back when we had a single docker container in our prior project, there was stuff going on automatically
behind the scenes when we passed our code over to elastic beanstalk. We didn't have to put together any 
custom configuration or anything to tell elastic beanstalk that it needs to take this docker file and build it and 
run the image that comes out of that. That was an automated process. We simply took our project directory
with the dockerfile in the root directory threw it over to elastic beanstalk which then built it and 
ran the image that comes out of that.

This time around we are in a different situation. We don't have a single docker file anymore. We have multiple
folders, each with its own docker file. So now if we toss this over to elastic beanstalk, it won't know which
one to run or when. So now we need to add another layer to tell elastic beanstalk how to treat our project.

So we are going to create a file, Dockerrun.aws.json to tell elastic beanstalk exactly where to pull all of our images from,
what resources to allocate to each one, how to set up some port mappings, and some associated information. The difference
is that in a docker-compose.yaml, we refer to them as services, we build an image using a docker file, in Dockerrun.aws.json 
they are container-definitions where we say to elastic beanstalk, go pull the image from docker hub and use it for each of
the container definitions we have added. See DockerrunAWS.png


https://jsonlint.com   <--- use this to perform a quick validation of any json you write (checks for missing delimiters)